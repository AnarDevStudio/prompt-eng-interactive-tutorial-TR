{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bölüm 1: Temel Prompt Yapısı\n",
    "- [Ders](__#lesson__)\n",
    "- [Alıştırmalar](__#exercises__)\n",
    "- [Örnek Oyun Alanı](__#example-playground__)\n",
    "## Kurulum\n",
    "API anahtarınızı yüklemek ve `get_completion` yardımcı fonksiyonunu oluşturmak için aşağıdaki kurulum hücresini çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic --quiet\n",
    "\n",
    "# utils paketinden hints modülünü içe aktar\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import hints\n",
    "\n",
    "# Python'un yerleşik düzenli ifade kütüphanesini içe aktar\n",
    "import re\n",
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "%store -r MODEL_NAME\n",
    "%store -r AWS_REGION\n",
    "\n",
    "client = AnthropicBedrock(aws_region=AWS_REGION)\n",
    "\n",
    "def get_completion(prompt, system=''):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        system=system\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ders\n",
    "Anthropic iki API sunar: eski [Text Completions API](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-text-completion.html) ve güncel [Messages API](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html). Bu eğitim için yalnızca Messages API'yi kullanacağız.\n",
    "Messages API kullanarak Claude'a yapılan bir çağrı için en azından aşağıdaki parametreler gereklidir:\n",
    "- `model`: çağırmayı planladığınız modelin [API model adı](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns)\n",
    "- `max_tokens`: durmadan önce üretilecek maksimum token sayısı. Claude'un bu maksimuma ulaşmadan durabileceğini unutmayın. Bu parametre yalnızca üretilecek mutlak maksimum token sayısını belirtir. Ayrıca bu bir *kesin* durdurma olduğundan, Claude'un kelime veya cümle ortasında üretmeyi durdurmasına neden olabilir.\n",
    "- `messages`: giriş mesajlarından oluşan bir dizi. Modellerimiz, dönüşümlü `user` ve `assistant` konuşma turları üzerinde çalışmak üzere eğitilmiştir. Yeni bir `Message` oluştururken, önceki konuşma turlarını messages parametresiyle belirtirsiniz ve model daha sonra konuşmada bir sonraki `Message`'ı oluşturur.\n",
    "  - Her giriş mesajı, bir `role` ve `content` içeren bir nesne olmalıdır. Tek bir `user` rolü mesajı belirtebilir veya birden fazla `user` ve `assistant` mesajı ekleyebilirsiniz (bu durumda dönüşümlü olmalıdır). İlk mesaj her zaman `user` rolünü kullanmalıdır.\n",
    "Ayrıca şu gibi isteğe bağlı parametreler de vardır:\n",
    "- `system`: sistem promptu - bunun hakkında aşağıda daha fazla bilgi.\n",
    "- `temperature`: Claude'un yanıtındaki değişkenlik derecesi. Bu dersler ve alıştırmalar için `temperature`'ı 0 olarak ayarladık.\n",
    "Tüm API parametrelerinin tam listesi için [API dokümantasyonumuzu](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-claude.html) ziyaret edin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Örnekler\n",
    "Claude'un doğru biçimlendirilmiş bazı promptlara nasıl yanıt verdiğine bir göz atalım. Aşağıdaki hücrelerin her biri için hücreyi çalıştırın (`shift+enter`) ve Claude'un yanıtı bloğun altında görünecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Selam Claude, Nasilsin?\"\n",
    "\n",
    "# Claude cevabini print ediyoruz\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"bana okyanusun ne renk oldugunu soylermisin?\"\n",
    "\n",
    "# Claude cevabini print ediyoruz\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Celine Dion ne zaman dogmusdu?\"\n",
    "\n",
    "# Claude cevabini print ediyoruz\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi doğru Messages API biçimlendirmesini içermeyen bazı promptlara bakalım. Bu hatalı biçimlendirilmiş promptlar için Messages API bir hata döndürür.\n",
    "İlk olarak, `messages` dizisinde `role` ve `content` alanlarının bulunmadığı bir Messages API çağrısı örneğimiz var."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ **Uyarı:** Prompttaki messages parametresinin yanlış biçimlendirilmesi nedeniyle, aşağıdaki hücre bir hata döndürecektir. Bu beklenen bir davranıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude cevabini aliyoruz\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Merhaba Claude, Nasilsin?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Claude cevabini print ediyoruz\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İşte `user` ve `assistant` rolleri arasında dönüşümlü geçiş yapmayan bir prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ **Warning:** Due to the lack of alternation between `user` and `assistant` roles, Claude will return an error message. This is expected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude cevabini aliyoruz\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"Celine Dion ne zaman dogmusdu?\"},\n",
    "          {\"role\": \"user\", \"content\": \"ayni zamanda bana onun hakkinda bazi bilgiler ver\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Claude cevabini print ediyoruz\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user` ve `assistant` mesajları **MUTLAKA dönüşümlü olmalıdır** ve mesajlar **MUTLAKA bir `user` turu ile başlamalıdır**. Bir promptta birden fazla `user` & `assistant` çifti bulunabilir (sanki çok turlu bir konuşmayı simüle ediyormuş gibi). Ayrıca, Claude'un kaldığınız yerden devam etmesi için son bir `assistant` mesajına kelimeler koyabilirsiniz (bunun hakkında sonraki bölümlerde daha fazla bilgi).\n",
    "#### Sistem Promptları\n",
    "**Sistem promptları** da kullanabilirsiniz. Sistem promptu, \"User\" turunda Claude'a bir soru veya görev sunmadan önce **bağlam, talimatlar ve yönergeler sağlamanın** bir yoludur.\n",
    "Yapısal olarak, sistem promptları `user` & `assistant` mesajlarının listesinden ayrı olarak bulunur ve bu nedenle ayrı bir `system` parametresine aittir (not defterinin [Kurulum](__#setup__) bölümündeki `get_completion` yardımcı fonksiyonunun yapısına bakın).\n",
    "Bu eğitim boyunca, sistem promptu kullanabileceğimiz her yerde, completions fonksiyonunuzda size bir `system` alanı sağladık. Sistem promptu kullanmak istemiyorsanız, `SYSTEM_PROMPT` değişkenini basitçe boş bir dizeye ayarlayın."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sistem Promptu Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistem promptu\n",
    "SYSTEM_PROMPT = \"Yanıtınız her zaman konuşmayı ileriye taşıyan bir dizi eleştirel düşünme sorusu olmalıdır (sorularınıza cevap vermemelisiniz). Kullanıcının sorusunu gerçekten yanıtlamayın.\"\n",
    "# Prompt\n",
    "PROMPT = \"Gokyuzu neden mavi?\"\n",
    "\n",
    "# Claude cevabini print ediyoruz\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neden sistem promptu kullanmalı? **İyi yazılmış bir sistem promptu, Claude'un performansını** çeşitli şekillerde artırabilir, örneğin Claude'un kurallara ve talimatlara uyma yeteneğini artırır. Daha fazla bilgi için, Claude ile [sistem promptlarını nasıl kullanacağınız](__https://docs.anthropic.com/claude/docs/how-to-use-system-prompts__) hakkındaki dokümantasyonumuzu ziyaret edin.\n",
    "Şimdi bazı alıştırmalara geçeceğiz. Yukarıdaki içeriği değiştirmeden ders promptlarıyla denemeler yapmak isterseniz, [**Örnek Oyun Alanı**](__#example-playground__)'nı ziyaret etmek için ders not defterinin en altına kaydırın."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Alıştırmalar\n",
    "- [Alıştırma 1.1 - Üçe Kadar Sayma](#exercise-11---counting-to-three)\n",
    "- [Alıştırma 1.2 - Sistem Promptu](#exercise-12---system-prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alıştırma 1.1 - Üçe Kadar Sayma\n",
    "Uygun `user` / `assistant` biçimlendirmesini kullanarak, Claude'un **üçe kadar saymasını** sağlamak için aşağıdaki `PROMPT`'u düzenleyin. Çıktı ayrıca çözümünüzün doğru olup olmadığını da gösterecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - degistire bileceyin tek yer\n",
    "PROMPT = \"[bu yaziyi degistir]\"\n",
    "\n",
    "# claude cevabini aliyoruz\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Alıştırma doğruluğunu değerlendirmek için fonksiyon\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# claude cevabini print ediyoruz ve doğruluğunu değerlendirmek\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"bu alisdirma cozulmusdur:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ İpucu isterseniz, aşağıdaki hücreyi çalıştırın!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alıştırma 1.2 - Sistem Promptu\n",
    "Claude'un 3 yaşında bir çocuk gibi yanıt vermesini sağlamak için `SYSTEM_PROMPT`'u değiştirin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistem promptu - degistire bileceyin tek yer\n",
    "SYSTEM_PROMPT = \"[bu yaziyi degistir]\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"gok ne kadar buyuk?\"\n",
    "\n",
    "# claude cevabi\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Alıştırma doğruluğunu değerlendirmek için fonksiyon\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# claude cevabini print ediyoruz ve doğruluğunu değerlendirmek\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"bu alisdirma cozulmusdur:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ İpucu isterseniz, aşağıdaki hücreyi çalıştırın!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tebrikler!\n",
    "\n",
    "eyer simdiyine kadar butun Alistirmalari cozduyseniz, diyer bolume gecmeye hazirsinzi demekdir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Örnek Oyun Alanı\n",
    "Bu alan, bu derste gösterilen prompt örnekleriyle özgürce deneme yapmanız ve Claude'un yanıtlarını nasıl etkileyebileceğini görmek için promptları değiştirmeniz için bir alandır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Merhaba Claude, nasılsın?\"\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claude cevabini al\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Hi Claude, how are you?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claude cevabini al\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistem promptu\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
